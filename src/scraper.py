import os
import json
import requests


class KSongScraper:
    DOWNLOAD_PATH = "downloads"
    TEXT_BEFORE_JSON = "window.__DATA__ = "
    TEXT_AFTER_JSON = "; </script>"

    def __init__(self, download_path=None):
        self.download_path = download_path or self.DOWNLOAD_PATH
        self.data = {}

    def fetch_page(self, url):
        """å¾ç¶²å€ç²å– HTML å…§å®¹"""
        print(f"Fetching {url} ...")
        response = requests.get(url)
        if response.status_code != 200:
            raise Exception(
                f"Failed to fetch page, status code: {response.status_code}")
        return response.text

    def extract_json_data(self, content):
        """å¾ HTML æå– JSON æ•¸æ“š"""
        start_idx = content.find(self.TEXT_BEFORE_JSON)
        if start_idx == -1:
            raise ValueError("Could not find song data in the page")

        content = content[start_idx + len(self.TEXT_BEFORE_JSON):]
        end_idx = content.find(self.TEXT_AFTER_JSON)
        if end_idx == -1:
            raise ValueError("Could not extract valid JSON from page")

        return json.loads(content[:end_idx])

    def parse(self, url):
        """è§£ææ­Œæ›²é é¢ï¼Œæå–æ‰€æœ‰æ­Œæ›²è³‡è¨Š"""
        content = self.fetch_page(url)
        self.data = self.extract_json_data(content)

        # æå–æ‰€æœ‰æ­Œæ›²è³‡è¨Š
        detail = self.data.get("detail", {})

        # æ‰“å°å‡ºæ‰€æœ‰å¯ç”¨çš„è³‡è¨Š
        print("\n=== å®Œæ•´æ­Œæ›²è³‡è¨Š ===")
        for key, value in detail.items():
            print(f"{key}: {value}")

        # æ•´ç†æˆå­—å…¸
        song_info = {
            "song_name": detail.get("song_name", "Unknown"),
            "play_url": detail.get("playurl", "N/A"),
            "singer": detail.get("nick", "Unknown"),
            "song_id": detail.get("song_id", "Unknown"),
            "cover": detail.get("cover", "N/A"),
            "comment_count": detail.get("comment_cnt", 0),
            "like_count": detail.get("like_cnt", 0),
            "share_count": detail.get("share_cnt", 0),
            "play_count": detail.get("play_cnt", 0),
            "duration": detail.get("duration", 0),
        }

        # å­˜æˆ JSON æª”æ¡ˆ
        json_path = os.path.join(
            self.download_path, f"{song_info['song_name']}.json")
        os.makedirs(self.download_path, exist_ok=True)
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(song_info, f, ensure_ascii=False, indent=4)

        print(f"\nğŸµ æ­Œæ›²è³‡è¨Šå·²å­˜æª”: {json_path}")

        return song_info

    def download_audio(self):
        """ä¸‹è¼‰æ­Œæ›²éŸ³è¨Š"""
        play_url = self.data.get("detail", {}).get("playurl")
        song_name = self.data.get("detail", {}).get("song_name", "unknown")

        if not play_url or play_url == "N/A":
            print("No valid play URL found, skipping download.")
            return

        print(f"Downloading {song_name}...")
        response = requests.get(play_url)
        audio_path = os.path.join(self.download_path, f"{song_name}.m4a")

        with open(audio_path, "wb") as f:
            f.write(response.content)

        print(f"Download finished: {audio_path}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="KSong Scraper")
    parser.add_argument("url", type=str, help="URL of the song page")

    args = parser.parse_args()

    scraper = KSongScraper()
    song_data = scraper.parse(args.url)

    print("\n=== æå–çš„æ­Œæ›²è³‡è¨Š ===")
    print(json.dumps(song_data, indent=4, ensure_ascii=False))
